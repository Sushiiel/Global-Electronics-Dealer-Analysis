{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede28900-c30a-4fc0-9350-9d2f332ea8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read C:/Users/Hp/Desktop/Project1\\Customers.csv with encoding utf-8. Trying next encoding...\n",
      "Processing Customers.csv\n",
      "NaN values before replacement:\n",
      "CustomerKey     0\n",
      "Gender          0\n",
      "Name            0\n",
      "City            0\n",
      "State Code     10\n",
      "State           0\n",
      "Zip Code        0\n",
      "Country         0\n",
      "Continent       0\n",
      "Birthday        0\n",
      "dtype: int64\n",
      "\n",
      "Processing Data_Dictionary.csv\n",
      "NaN values before replacement:\n",
      "Table          0\n",
      "Field          0\n",
      "Description    0\n",
      "dtype: int64\n",
      "\n",
      "Processing Exchange_Rates.csv\n",
      "NaN values before replacement:\n",
      "Date        0\n",
      "Currency    0\n",
      "Exchange    0\n",
      "dtype: int64\n",
      "\n",
      "Processing Products.csv\n",
      "NaN values before replacement:\n",
      "ProductKey        0\n",
      "Product Name      0\n",
      "Brand             0\n",
      "Color             0\n",
      "Unit Cost USD     0\n",
      "Unit Price USD    0\n",
      "SubcategoryKey    0\n",
      "Subcategory       0\n",
      "CategoryKey       0\n",
      "Category          0\n",
      "dtype: int64\n",
      "\n",
      "Processing Sales.csv\n",
      "NaN values before replacement:\n",
      "Order Number         0\n",
      "Line Item            0\n",
      "Order Date           0\n",
      "Delivery Date    49719\n",
      "CustomerKey          0\n",
      "StoreKey             0\n",
      "ProductKey           0\n",
      "Quantity             0\n",
      "Currency Code        0\n",
      "dtype: int64\n",
      "\n",
      "Processing Stores.csv\n",
      "NaN values before replacement:\n",
      "StoreKey         0\n",
      "Country          0\n",
      "State            0\n",
      "Square Meters    1\n",
      "Open Date        0\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import os\n",
    "\n",
    "# List of CSV files and their corresponding table names\n",
    "csv_files = [\n",
    "    ('Customers.csv', 'Customers'),\n",
    "    ('Data_Dictionary.csv', 'Data_Dictionary'),\n",
    "    ('Exchange_Rates.csv', 'Exchange_Rates'),\n",
    "    ('Products.csv', 'Products'),\n",
    "    ('Sales.csv', 'Sales'),\n",
    "    ('Stores.csv', 'Stores')\n",
    "]\n",
    "\n",
    "# Connect to the MySQL database\n",
    "try:\n",
    "    conn = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='595162sushiielA@',\n",
    "        database='project22'\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "except mysql.connector.Error as err:\n",
    "    print(f\"Error connecting to MySQL: {err}\")\n",
    "    exit(1)\n",
    "\n",
    "# Folder containing the CSV files\n",
    "folder_path = 'C:/Users/Hp/Desktop/Project1'\n",
    "\n",
    "def get_sql_type(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return 'INT'\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return 'FLOAT'\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return 'BOOLEAN'\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return 'DATETIME'\n",
    "    else:\n",
    "        return 'TEXT'\n",
    "\n",
    "def read_csv_with_encodings(file_path, encodings=['utf-8', 'ISO-8859-1', 'Windows-1252']):\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            return pd.read_csv(file_path, encoding=encoding)\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Failed to read {file_path} with encoding {encoding}. Trying next encoding...\")\n",
    "    raise ValueError(f\"Unable to read {file_path} with any of the specified encodings.\")\n",
    "\n",
    "for csv_file, table_name in csv_files:\n",
    "    file_path = os.path.join(folder_path, csv_file)\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file into a pandas DataFrame with different encodings\n",
    "        df = read_csv_with_encodings(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to read {csv_file}: {e}\")\n",
    "        continue  # Skip to the next file\n",
    "\n",
    "    # Replace NaN with None to handle SQL NULL\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # Debugging: Check for NaN values\n",
    "    print(f\"Processing {csv_file}\")\n",
    "    print(f\"NaN values before replacement:\\n{df.isnull().sum()}\\n\")\n",
    "\n",
    "    # Clean column names\n",
    "    df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]\n",
    "\n",
    "    # Generate the CREATE TABLE statement with appropriate data types\n",
    "    columns = ', '.join([f'`{col}` {get_sql_type(df[col].dtype)}' for col in df.columns])\n",
    "    create_table_query = f'CREATE TABLE IF NOT EXISTS `{table_name}` ({columns})'\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "    # Insert DataFrame data into the MySQL table\n",
    "    try:\n",
    "        # Create a list of tuples for batch insert\n",
    "        data_tuples = [\n",
    "            tuple(None if pd.isna(x) else x for x in row) for row in df.itertuples(index=False)\n",
    "        ]\n",
    "        sql = f\"INSERT INTO `{table_name}` ({', '.join(['`' + col + '`' for col in df.columns])}) VALUES ({', '.join(['%s'] * len(df.columns))})\"\n",
    "        cursor.executemany(sql, data_tuples)\n",
    "\n",
    "        # Commit the transaction for the current CSV file\n",
    "        conn.commit()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to insert data for {csv_file}: {e}\")\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b32ea9-3902-437f-8c26-1036d1cadc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mysql-connector-python in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (9.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb84e5c-6707-4414-8a2c-d5f380d1d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7a3612-2bbf-43f3-83b9-55cfd0a84f1d",
   "metadata": {},
   "source": [
    "What types of products does the company sell, and where are customers located?\n",
    "\n",
    "Are there any seasonal patterns or trends for order volume or revenue?\n",
    "\n",
    "How long is the average delivery time in days? Has that changed over time?\n",
    "\n",
    "Is there a difference in average order value (AOV) for online vs. in-store sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e5c2ff-086b-49c2-acba-7f8d0ada0594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_12276\\1751872455.py:9: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  product_types = pd.read_sql_query(product_types_query, conn)\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "MySQL Connection not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m product_types_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124mSELECT DISTINCT Subcategory, COUNT(Product_Name) AS Product_Count\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124mFROM Products\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mGROUP BY Subcategory;\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 9\u001b[0m product_types \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproduct_types_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Types:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, product_types)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2729\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\pandas\\io\\sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery must be a string unless using sqlalchemy.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2671\u001b[0m args \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [params]\n\u001b[1;32m-> 2672\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\mysql\\connector\\connection.py:1263\u001b[0m, in \u001b[0;36mMySQLConnection.cursor\u001b[1;34m(self, buffered, raw, prepared, cursor_class, dictionary, named_tuple)\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unread_result()\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected():\n\u001b[1;32m-> 1263\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMySQL Connection not available\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(cursor_class, MySQLCursor):\n",
      "\u001b[1;31mOperationalError\u001b[0m: MySQL Connection not available"
     ]
    }
   ],
   "source": [
    "# Question 1: Types of Products and Customer Locations\n",
    "# 1a. Product Types\n",
    "import pandas as pd\n",
    "product_types_query = \"\"\"\n",
    "SELECT DISTINCT Subcategory, COUNT(Product_Name) AS Product_Count\n",
    "FROM Products\n",
    "GROUP BY Subcategory;\n",
    "\"\"\"\n",
    "product_types = pd.read_sql_query(product_types_query, conn)\n",
    "print(\"Product Types:\\n\", product_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef29d2-4ba2-47bb-a931-08324b58d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b. Customer Locations\n",
    "customer_locations_query = \"\"\"\n",
    "SELECT DISTINCT City || ' ' || State || ' ' || Country AS Customer_Location\n",
    "FROM Customers;\n",
    "\"\"\"\n",
    "customer_locations = pd.read_sql_query(customer_locations_query, conn)\n",
    "print(\"Customer Locations:\\n\", customer_locations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9b88e-9a84-4d54-a427-cd6dd8e61596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Monthly and Quarterly Order Volumes and Revenue Trends\n",
    "# Add `Order_con` and `Del_con` to Sales to work with datetime columns in Pandas\n",
    "sales_df['Order_con'] = pd.to_datetime(sales_df['Order_Date'], format='%m/%d/%Y')\n",
    "sales_df['Del_con'] = pd.to_datetime(sales_df['Delivery_Date'], format='%m/%d/%Y')\n",
    "sales_df.to_sql('converted', conn, index=False, if_exists='replace')\n",
    "\n",
    "# Monthly Order Volume and Revenue\n",
    "monthly_trends_query = \"\"\"\n",
    "SELECT strftime('%Y-%m', Order_con) AS Order_Month, \n",
    "       COUNT(Order_Number) AS Total_Orders, \n",
    "       SUM(Revenue) AS Total_Revenue\n",
    "FROM converted\n",
    "GROUP BY Order_Month;\n",
    "\"\"\"\n",
    "monthly_trends = pd.read_sql_query(monthly_trends_query, conn)\n",
    "print(\"Monthly Order Volumes and Revenue:\\n\", monthly_trends)\n",
    "\n",
    "# Quarterly Order Volume and Revenue\n",
    "quarterly_trends_query = \"\"\"\n",
    "SELECT strftime('%Y-Q%Y', Order_con) AS Order_Quarter, \n",
    "       COUNT(Order_Number) AS Total_Orders, \n",
    "       SUM(Revenue) AS Total_Revenue\n",
    "FROM converted\n",
    "GROUP BY Order_Quarter;\n",
    "\"\"\"\n",
    "quarterly_trends = pd.read_sql_query(quarterly_trends_query, conn)\n",
    "print(\"Quarterly Order Volumes and Revenue:\\n\", quarterly_trends)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe870d-d591-4938-97f5-120863a027b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Average Delivery Time\n",
    "delivery_time_query = \"\"\"\n",
    "SELECT AVG(julianday(Del_con) - julianday(Order_con)) AS Average_Delivery_Time\n",
    "FROM converted\n",
    "WHERE Del_con IS NOT NULL;\n",
    "\"\"\"\n",
    "average_delivery_time = pd.read_sql_query(delivery_time_query, conn)\n",
    "print(\"Average Delivery Time (days):\\n\", average_delivery_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d7bc5-87dc-4d91-a500-d609849e4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Seasonal Trends for Order Volume and Revenue\n",
    "# Use Pandas for advanced time-based analysis\n",
    "sales_df['Order_Month'] = sales_df['Order_con'].dt.to_period(\"M\")\n",
    "monthly_orders = sales_df.groupby('Order_Month')['Order_Number'].count()\n",
    "monthly_revenue = sales_df.groupby('Order_Month')['Revenue'].sum()\n",
    "print(\"Monthly Order Volume and Revenue Trends:\\n\", pd.DataFrame({'Orders': monthly_orders, 'Revenue': monthly_revenue}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41feded5-2ab6-4f78-8269-e8415b7981b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Most Common Products by Region\n",
    "# Join Customers and Sales data to analyze by region\n",
    "common_products_region_query = \"\"\"\n",
    "SELECT c.Country, c.State, c.City, p.Subcategory, COUNT(s.Order_Number) AS Order_Count\n",
    "FROM Sales s\n",
    "JOIN Customers c ON s.Customer_ID = c.Customer_ID\n",
    "JOIN Products p ON s.Product_ID = p.Product_ID\n",
    "GROUP BY c.Country, c.State, c.City, p.Subcategory\n",
    "ORDER BY Order_Count DESC;\n",
    "\"\"\"\n",
    "common_products_region = pd.read_sql_query(common_products_region_query, conn)\n",
    "print(\"Most Common Products by Region:\\n\", common_products_region)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
